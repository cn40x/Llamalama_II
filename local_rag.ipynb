{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import ollama\n",
    "\n",
    "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "from langchain_community.document_loaders import OnlinePDFLoader\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.embeddings.base import Embeddings\n",
    "\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OllamaEmbeddings(Embeddings):\n",
    "    def __init__(self, model: str = 'mxbai-embed-large'):\n",
    "        self.model = model\n",
    "\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        return [ollama.embeddings(model=self.model, prompt=text)['embedding'] for text in texts]\n",
    "\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        return ollama.embeddings(model=self.model, prompt=text)['embedding']\n",
    "    \n",
    "def get_relevant_context(query: str, vector_db: Chroma, top_k: int = 3, threshold: float = 0.8) -> str:\n",
    "    \n",
    "    query_embedding = torch.tensor(OllamaEmbeddings().embed_query(query))\n",
    "    \n",
    "\n",
    "    all_embeddings = vector_db._collection.get(include=['embeddings', 'documents'])\n",
    "    embeddings = torch.tensor(all_embeddings['embeddings'])\n",
    "    documents = all_embeddings['documents']\n",
    "\n",
    "    cos_scores = torch.nn.functional.cosine_similarity(query_embedding.unsqueeze(0), embeddings)\n",
    "    \n",
    "    filtered_scores = cos_scores[cos_scores >= threshold]\n",
    "    if len(filtered_scores) == 0:\n",
    "        return \"No relevant documents found.\"\n",
    "\n",
    "    top_k = min(top_k, len(filtered_scores))\n",
    "    \n",
    "    \n",
    "    top_indices = torch.topk(filtered_scores, k=top_k)[1].tolist()\n",
    "    \n",
    "    res = \"\"\n",
    "    for i, idx in enumerate(top_indices):\n",
    "        res += f\"{i+1}. {documents[idx]},\\n\\n\"\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kunkerdthaisong/Llamalama_II/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "loader = UnstructuredPDFLoader(file_path=\"./Grammar_Cheatsheet.pdf\")\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_function = OllamaEmbeddings(model='mxbai-embed-large')\n",
    "\n",
    "vector_db = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embedding_function,\n",
    "    collection_name=\"local-rag\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<langchain_community.vectorstores.chroma.Chroma object at 0x31b2af830>\n"
     ]
    }
   ],
   "source": [
    "print(vector_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. The Official Rules\n",
      "\n",
      "“Data” is a Latin-based word and is the plural of “datum.”\n",
      "\n",
      "“Datum” is the singular version of “data.”\n",
      "\n",
      "Examples\n",
      "\n",
      "The data show that the hypothesis was correct. • One outlying datum point is fairly standard to see in experiments.\n",
      "\n",
      "Rules of Thumb,\n",
      "\n",
      "2. With that in mind, some of these rules skirt the official, unyielding rules of those who believe grammar to be prescriptive. Rather, they reflect how grammar is working today (for an example, check out data vs datum).\n",
      "\n",
      "Affect vs Effect,\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"what differ between Poor vs Pore vs Pour\"\n",
    "relevant_docs = get_relevant_context(query, vector_db)\n",
    "print(relevant_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llm_response(prompt, system_prompt=\"You are a helpful assistant. who help me study english and answer in briefly.\"):\n",
    "    searched=get_relevant_context(prompt,vector_db)\n",
    "    response = ollama.chat(model='phi3', messages=[\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'content': system_prompt,\n",
    "        },\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': prompt+f\",Here the User's querry (unnecessary): {searched},\",\n",
    "        }\n",
    "    ])\n",
    "    return response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As your English assistant:\\n\\n1. I can help ensure you write error-free sentences by checking for correct grammar and sentence structure when composing papers or essays in English. This will enhance the overall quality of your writing. However, it\\'s essential to understand that while avoiding grammatical mistakes is beneficial, developing a deeper understanding of language mechanics can truly improve as you write consistently.\\n\\n2. I am equipped with guides and tools designed to clarify commonly confused words in English—like homophones or frequently misused terms. This information will assist you while typing on your keyboard and prevent errors related to word choice, ultimately improving the clarity of your writing. Remember that practicing using these words correctly is crucial for mastery over time.\\n\\n3. Regarding \"advice\" versus \"advise,\" I can provide examples of their correct usage in sentences or offer exercises aimed at helping you distinguish between when to use each word, thus enhancing your understanding and command of the English language.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_llm_response(\"what can you do for help me study english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db.delete_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
